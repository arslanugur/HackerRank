> DATA STRUCTURES
             Primitive Data Structures (Build-in, System or Compiler Defined)
                  -->  int, char, float, pointer.. 
                  
                  -->  boolean: boolean
                  -->  numeric: character: char
                                integral: integer: byte, short, int, long
                                          floating-point: float, double 

         Non-Primitive Data Structures (User Defined)
                  -->  Array, List, Files,, String, Structure, Classes
                               |
1. Linear Data Structures      |  2. Non-Linear Data Structures
   - Arrays                    |     - Trees
   - Linked Lists              |     - Graphs
   - Stacks                    |     - (Hash) Tables
   - Queues                    |     - Sets
   - Files                     |     - Tries

> OPERATIONS in DS
- Traversing: Visiting each element of the data structure only once is called traversing.
- Searching:  Finding an element in a data structure that satisfies one or more conditions.
- Inserting:  Adding elements of the same type in a DS is called insertion.
              Elements can be added anywhere in the data structure.
- Deleting:   Removing an element from a data structure is called deletion.
              Elements can be removed from anywhere in the Data Structure.
- Sorting:    Sorting the elements in the data structure in ascending and descending order is called sorting.
- Merging:    Merging is the storage of elements located in two different data files by combining them into one data file.


> NOTATIONS
Big-Oh:    f(x) = O(g(x))  --> a problem will not be not bigger/upper than this (shows up limit to solve a problem)
                           --> in the worst situation, it equals O(g(x))
                           --> Asymptotic Notation
                           --> tüm x > k için eşitliği sağlayan bir C, k var.
                           --> |f(x)| equal< C.|g(x)|
           Example:
           f(x) = x^2       g(x) = x^2 + 2x + 1
                   f(x) = O(g(x))
                    x^2 = O(x^2+2x+1)
           x>0 -->  x^2 equal< x^2+2x+1
                   f(x) equal< g(x)
           Parameters: C=1, k=0
           
Big-Omega: f(x) = Ω(g(x))  --> not smaller
Big-Theta: f(x) = Θ(g(x))  --> the same degree


> INCREMENT FUNCTIONS
f: R -> R        g: R -> R

"Ölçebildiğiniz güç sizindir. Gelecekte ispatını gösteren şey makuldur."

> GROWTH RATE
f ve g tamsayı/reel sayı kümesinden "reel sayılara" tanımlanmış olan fonksiyonlar olsun
eğer x > k olduğunda |f(x)| equal< C|g(x)| oluyorsa 
ve bu eşitsizliği sağlayan C ve k gibi sabit sayılar (koşulu sağlayan şahitler) varsa 
bu durumda f(x) = O(g(x)) olmaktadır.

Input         Algorithm 1    Algorithm 2
n             5000n          [1.1^n]
10            50000          3
100           500000         13781
1000          5000000        2.5*10^41
1000000       5*10^9         4.8*10^41392


> FUNCTIONS TIME COMPLEXITY GROWTH (by sorting to fast/bad from slow/good)
Cost:  1 --> log n --> n --> n log n --> n^2 --> n^3 --> 2^n --> n!
       
       Classification of Complexity
       1: Eğer yapılacak iş sadece basit bir yapıdaysa, sabit bir zamanı var.
   log n: Eğer her bir yapacağım iş, problemi belli bir alt parçaya bölmek/parçalamak* ise bu log n sürede yapılır.
       n: Eğer her bir işi ayrı ayrı konumlarsak, n tane iş varsa bunu n zamanda yapacağımızı gösterir.
 n log n: Eğer n işini her bir aşamada n parçaya bölüp, her bir parçanın içinde de n sürede işi yapacağımızı gösterir. 
     n^2: Eğer n tane işi birlikte yapacaksam n^2 sürede yapılır.
     2^n: Eğer bunlar birbirleriyle bağlantılı olarak kümülatif şekilde (üst üste gidiyorsa) artıyorsa 2^n sürede yapılır.
      n!: Eğer her bir adımda n tane işi gerçekleştireceksek n! sürede yapılır.          
             
        *Logaritma, bir ayrım/parçalama işlemidir.           

> ALGORITHMS with DS
# Data Structures
Arrays
- Kadane's Algorithm (Max Subarray Problem)
- Floyd's Cycle Detection Algorithm (Floyd's Tortoise and Hare)
- KMP(Knuth-Morris-Pratt) Algorithm - Class: String Search Algorithms, DS: String
- Quickselect Algorithm
- Boyer-Moore Majority Vote (BMMV) Algorithm
- Sorting Algorithms Class

Graphs
  Applications:
    - To define flow of computation
    - In WWW, web pages are considered to be the vertices
  Common Interview Questions:
    - Find shortest path between two vertices
    - Check if a path exists between two vertices
    - Find "Mother Vertex" in a graph
    - Check if a graph is a tree or not
  Algorithms:
    - Kruskal's Algorithm
    - Dijkstra's Algorithm
    - Bellman Ford Algorithm
    - Floyd-Warshall Algorithm (to find shortest paths), All-Pairs Shortest Path Problem for weighted graphs
    - Topological Sort Algorithm
    - Flood Fill Algorithm
    - Lee Algorithm


Linked Lists
  Applications:
    - Implement stacks, queues, and hash tables
    - Create directories
    - Dynamic memory allocation
  Common Interview Questions:
    - Reverse a linked list 
    - Detect loop in a linked list
    - Find the middle value in a linked list
    - Remove loop in a linked list

Stacks
  Applications:
    - Backtracking to a previous state
    - Expression evalution and conversion
    - Used for Memory Management
  Common Interview Questions:
    - Use stack to check for balanced parenthesis
    - iInplement two stacks in an array
    - Next greater element using a stack
    - Convert infix to postfix using stack
    
Queues
  Applications:
    - To reverse strings
    - To traverse the nodes of a binary tree
    - To search the vertices of a graph
  Common Interview Questions:
    - Reverse first kth elements of a queue 
    - Generate binary numbers from 1 to n using a queue
    - Implement stack using a queue
    
Hash Tables
  Applications:
    - When a resource is shared by multiple customers
    - Password verification
    - Linking file name and path
  Common Interview Questions:
    - Find symmetric pairs in an array 
    - Union and Intersection of lists using Hashing
    - Find a pair with given sum
    - Find the largest subarray with 0 sum
    
    
    
 
##### Divide and Conquer Approach (An Algorithm Design Paradigm)
      An Algorithm that divides the problems in two/smaller parts 
      and then combined/added together to produce the problem's final solution
- Example: Merge Sort Code
def merge_sort(arr):
  if len(arr) < 2
    return arr
    
  else:
    mid = len(arr)//2
    left_part = merge_sort(arr[:mid])
    right_part = merge_sort(arr[mid:])
    return join_sorted(left_part, right_part)


##### Brute Force Search (Problem-Solving Technique, An Algorithm Paradigm )
      A brute force algorithm simply tries all possibities 
      until a satisfactory solution is found
- Example: Naive Algorithm to find a pair sums up to k (tries every possible layer)
def find_pair(arr, k):
  for i in range(len(arr)):
    for j in range(i+1, len(arr)):
      if (arr[i]+arr[j]) == k:
        return (i, j)
  return(-1, -1)


> ALGORITHMS' CLASSES
                          SPACE and TIME COMPLEXITY
Sorting Algorithms:   Best          Average       Worst
- Selection Sort      Ω(n^2)        Θ(n^2)        O(n^2)            2
- Bubble Sort         Ω(n)          Θ(n^2)        O(n^2)            3
- Insertion Sort      Ω(n)          Θ(n^2)        O(n^2)
- Heap Sort           Ω(n log(n))   Θ(n log(n))   O(n log(n))
- Quick Sort          Ω(n log(n))   Θ(n log(n))   O(n^2)
- Merge Sort          Ω(n log(n))   Θ(n log(n))   O(n log(n))       1
- Bucket/Bin Sort     Ω(n+k)        Θ(n+k)        O(n^2)            DS: Array
- Radix Sort          Ω(nk)         Θ(nk)         O(nk)             DS: Array
- Counting Sort
- Tim Sort

                          SPACE and TIME COMPLEXITY
Searching Algorithms: Best          Average       Worst
- Linear Search       Ω(1)                        O(n)               DS: Array
- Binary Search       Ω(1)                        O(n log(n))        DS: Array
- Depth First Search                                                 DS: Graph
- Bread First Search                                                 DS: Graph
- Jump/Block Search

Binary Tree
      In a DS, a BT is a tree in which each node has only at most two children 
      which are called "left child" and "right child".
      

##### Greedy Algorithms
      In this approach, decisions are taken 
      on the basis of the information currently available without worrying about the future
      The approach doesn't relook at the previous chosen solution.
      The method tries to find/chooses the best/most (optimal) solution/move at each step.
      The first step is chosen in such a way that it gives immediate benefit.
      This Approach/These Algorithms are mainly used for solving optimization problems
      The method doesn't guarantee/provide that we will be able to find a optimal solution in many problems.
      However, the method gives near optimal solution in a reasonable time 
      and it is efficient in many cases and easy to implement
      Hence, Greedy Algorithm is an algorithmic paradigm which is based on inference
Components of Greedy Algorithms
- Candidate State: The solution is created by this set
- Selection Function: It's used to add the best candidate to the solution
- Feasibility Function: It's used to determine whether the candidate can be used to contribute to the solution.
- Objective Function: It's used to assign a value to a solution.
- Solution Function: It's used to indicate whether a complete solution has been obtained

Greedy Algorithms
- Huffman Coding (for a Huffman Tree)
- Fractional Knapsack Problem
- Activity Selection
- Job Sequencing Problem
- Travelling Salesman Problem
- Decision Tree
- Dijkstra's Algorithm (for Graph Search and Short Path Finding)
- Kruskal's Algorithm (to construct a Minimum Spanning Tree)
- Prim's Algorithm (to construct a Minimum Spanning Tree)

- Example: Activity Selection Problem (Maximum Number of Activities in finite amount of time)
def max_nb_activities(activities, time_limit):
  activities.sort()
  count = 0
  time = 0
  for activity in activities:
    if (time + activity) > time_limit:
      break
    else:
      count += 1
      time += activity
return count    


##### Dynamic Programming   
      - it loses Space but earns Time  (by Bellman)
      It solves complex problems by breaking'em into multiple simple subproblems
      and then it solves each of them once and then stores them for future use.
      DP is an optimization techniques for recursive solutions 
      that have overlapping subproblems, we use dp to solve a subproblem only seuence
- Fibonacci Number Series
- Sequence Alignment
- Knapsack Problem
- Tower of Hanoi Puzzle
- Shortest Path by Dijkastra
- Matrix Chain Multiplication
- A type of Balanced 0-1 Matrix
- CheckerBoard
- Egg Dropping Puzzle

- Example: nth term of Fibonacci Seuence
def fibonacci(n):
  dp = [0]*(n+1)
  dp[0] = 0
  dp[1] = 1
  for i in range(2, len(dp)):
    dp[i] = dp[i-1] + dp[i-2]
  return dp[n]



##### Recursive Programming 
      An Algorithm that calls itself repeatedly until the problem is solved. 
- Factorial
- Exponential
- Tower of Hanoi
- Tree Traversal
- DFS of Graph

- Example: To determine the sum of first n natural numbers
int fact(int n)
{
  if (n <= 1) //base case
    return 1;
  else
    return n * fact(n-1);
}


##### Backtracking Algorithm
      A backtracking algorithm solves a subproblem,
      and if it fails to solve the problem,
      it undoes the last step
      and starts again to find the solution to the problem.
      Another Definiton: 
      An algorithm that tries all the possible candidates
      and goes back as soon as it defects that the actual candidate can't be valid
      
- Example: Count subsets that sum up to k
def subsets_k(arr, k, i=0):
  if k == 0:
    return 1 #valid candidate
  elif k < 0 or i == len(arr):
    return 0 #unvalid candidate
  else:
    return subsets_k(arr[i], i+1) + subsets_k(arr, k, i+1)

Randomized Algorithm
      A randomized algorithm uses a random number at least once 
      during the computation to make a decision


Basic Algorithm
-Huffman Coding Compression Algorithm
-Euclid's Algorithm
-Union-Find Algorithm


Prime Numbers
- Sieve of Eratosthenes
- Primality test

Strings
- String Searching
- LCS
- Palindrome detection



